---
title: "Strings"
author: "Thomas Laurent"
date: "2017年7月1日"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#Loading package
library(tidyverse)
library(stringr)
```

#Basics

```{r}
#Double quote in a character
double_quote <- "\""
double_quote

x <- c("\"", "\\")

#Raw content of a string
writeLines(x)
```

##Non-English characters
```{r}
x <- "\u00b5"
x
```

##String length

```{r}
str_length(c("a", "R for data science", NA))
```

##Concatenate strings

```{r}
str_c("x", "y")

#Choosing the separator
str_c("x", "y", sep = ", ")
```

```{r}
#Concetenate with a vectorized object
str_c("prefix-", c("a", "b", "c"), "-suffix")
```

Object of length 0 are dropped
```{r}
name <- "Hadley"
time_of_day <- "morning"
birthday <- FALSE

str_c(
  "Good ", time_of_day, " ", name,
  if (birthday) " and HAPPY BIRTHDAY",
  "."
)
```

Concatenating objects of a vector

```{r}
str_c(c("x", "y", "z"), collapse = ", ")
```

##Subsetting strings

```{r}
x <- c("Apple", "Banana", "Pear")
str_sub(x, 1, 3)
#> [1] "App" "Ban" "Pea"
# negative numbers count backwards from end
str_sub(x, -3, -1)
```

If index is too high, no error will be displayed.

```{r}
str_sub("a", 1, 5)
```

Example changing the first letter of each word to lower case.
```{r}
x <- c("Apple", "Banana", "Pear")
str_sub(x, 1, 1) <- str_to_lower(str_sub(x, 1, 1))
x
```

##Locales

Specify the locale in the function accordingly

```{r}
x <- c("apple", "eggplant", "banana")

str_sort(x, locale = "en")  # English
#> [1] "apple"    "banana"   "eggplant"

str_sort(x, locale = "haw") # Hawaiian
```

#Matching patterns

Using str_view to visualize matching patterns

```{r}
x <- c("apple", "banana", "pear")
str_view(x, "an")
#"." to match any pattern
str_view(x,".a.")
```

```{r}
#Matching . in a string use \\ for non alphanumeric characters

str_view(c("abc", "a.c", "bef"), "a\\.c")
```

##Matching the start or the end of a string

```{r}
#Start
x <- c("apple", "banana", "pear")
str_view(x, "^a")

#End
str_view(x, "a$")
```

Matching a complete string

```{r}
x <- c("apple pie", "apple", "apple cake")
str_view(x, "apple")

#Delimit with ^ and $
str_view(x, "^apple$")
```

```{r}
#Using a loose condition e or a where | is placed
str_view(c("grey", "gray"), "gr(e|a)y")
```

##Repetitions

* ?: 0 or 1
* +: 1 or more
* *: 0 or more
```{r}
#Repetitions
x <- "1888 is the longest year in Roman numerals: MDCCCLXXXVIII"
str_view(x, "CC?")
str_view(x, "CC+")
str_view(x, 'C[LX]+')
```

You can also specify the number of matches precisely:

* {n}: exactly n
* {n,}: n or more
* {,m}: at most m
* {n,m}: between n and m

```{r}
#Exactly 2
str_view(x, "C{2}")

#2 or more observations
str_view(x, "C{2,}")

#between 2 and 3
str_view(x, "C{2,3}")
```

##Grouping and backreference

```{r}
str_view(fruit, "(..)\\1", match = TRUE)
```

#Tools

##Detect matches

```{r}
x <- c("apple", "banana", "pear")
str_detect(x, "e")

#Descriptive summary of matches

sum(str_detect(words, "^t"))
#> [1] 65
# What proportion of common words end with a vowel?
mean(str_detect(words, "[aeiou]$"))
```

```{r}
no_vowels_1 <- !str_detect(words, "[aeiou]")
# Find all words consisting only of consonants (non-vowels)
no_vowels_2 <- str_detect(words, "^[^aeiou]+$")
identical(no_vowels_1, no_vowels_2)
```

Subsetting elements matching the pattern

```{r}
words[str_detect(words, "x$")]
#> [1] "box" "sex" "six" "tax"
str_subset(words, "x$")
```

Filtering based on strings with dplyr
```{r}
df <- tibble(
  word = words, 
  i = seq_along(word)
)
df %>% 
  filter(str_detect(words, "x$"))
```

```{r}
df %>% 
  mutate(
    vowels = str_count(word, "[aeiou]"),
    consonants = str_count(word, "[^aeiou]")
  )
```

```{r}

```

Identify matches and extract the matched patterns
```{r}
#Creating a single regular expression
colours <- c("red", "orange", "yellow", "green", "blue", "purple")
colour_match <- str_c(colours, collapse = "|")
colour_match

has_colour <- str_subset(sentences, colour_match)
matches <- str_extract(has_colour, colour_match)
head(matches)
```

Extract strings matching at least once the condition

```{r}
more <- sentences[str_count(sentences, colour_match) > 1]
str_view_all(more, colour_match)
```

All matched patterns

```{r}
str_extract_all(more, colour_match, simplify = TRUE)
```

##Subset complex expressions

```{r}
noun <- "(a|the) ([^ ]+)"

has_noun <- sentences %>%
  str_subset(noun) %>%
  head(10)

has_noun %>% 
  str_extract(noun)

#Matrix of matched patterns
has_noun %>% 
  str_match(noun)
```

Using extract() from tidyr

```{r}
tibble(sentence = sentences) %>% 
  tidyr::extract(
    sentence, c("article", "noun"), "(a|the) ([^ ]+)", 
    remove = FALSE
  )
```

##Replacing matches

```{r}
x <- c("apple", "pear", "banana")
str_replace(x, "[aeiou]", "-")
#> [1] "-pple"  "p-ar"   "b-nana"
str_replace_all(x, "[aeiou]", "-")

#Multiple replacements using a vector
x <- c("1 house", "2 cars", "3 people")
str_replace_all(x, c("1" = "one", "2" = "two", "3" = "three"))

#Changing the order of words
sentences %>% 
  str_replace("([^ ]+) ([^ ]+) ([^ ]+)", "\\1 \\3 \\2") %>% 
  head(5)
```

##Splitting

```{r}
#Space separator
sentences %>%
  head(5) %>% 
  str_split(" ")

#Outputting a matrix
sentences %>%
  head(5) %>% 
  str_split(" ", simplify = TRUE)

#Finding line, words etc...
x <- "This is a sentence.  This is another sentence."
str_view_all(x, boundary("word"))
```

Finding the positiom of a match using str_locate()

```{r}
#Exemple
str_locate(c("1 house", "2 cars", "3 people"),"1")
```

#Other types of patterns

```{r}
bananas <- c("banana", "Banana", "BANANA")
str_view(bananas, regex("banana", ignore_case = TRUE))
```

At the beginning of each line
```{r}
x <- "Line 1\nLine 2\nLine 3"
str_extract_all(x, regex("^Line", multiline = TRUE))[[1]]
```

Expression for matching phone numbers

```{r}
phone <- regex("
  \\(?     # optional opening parens
  (\\d{3}) # area code
  [)- ]?   # optional closing parens, dash, or space
  (\\d{3}) # another three numbers
  [ -]?    # optional space or dash
  (\\d{3}) # three more numbers
  ", comments = TRUE)

str_match("514-791-8141", phone)
```

fixed() can be used to save processing times but does not follow human character comparison rules.
coll() performs comparison as human does.

```{r}
a1 <- "\u00e1"
a2 <- "a\u0301"
c(a1, a2)
#> [1] "á" "á"
a1 == a2

str_detect(a1, fixed(a2))

str_detect(a1, coll(a2))

#Subsetting using coll
str_subset(i, coll("i", ignore_case = TRUE))
#> [1] "I" "i"
str_subset(i, coll("i", ignore_case = TRUE, locale = "tr"))
```

#Other uses of regular expressions

```{r}
#Searching for file pattern in a directory
head(dir(pattern = "\\.Rmd$"))
```

#stringi

stringi packages provides more functions.